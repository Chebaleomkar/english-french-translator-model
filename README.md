# ğŸ‡«ğŸ‡·ğŸ‡¬ğŸ‡§ English-French Translator Model

![AI Powered](https://img.shields.io/badge/AI-Powered-blueviolet?style=for-the-badge)
![Transformers](https://img.shields.io/badge/Hugging%20Face-Transformers-yellow?style=for-the-badge)
![Python](https://img.shields.io/badge/Python-3.8%2B-blue?style=for-the-badge)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104.0-green?style=for-the-badge)

A robust and efficient Neutral Machine Translation (NMT) model fineâ€‘tuned for translating English text into French. This project leverages the **Helsinkiâ€‘NLP/opusâ€‘mtâ€‘enâ€‘fr** preâ€‘trained model, fineâ€‘tuned on the **Opus Books** dataset, and now ships with a lightweight **FastAPI** backend for easy deployment.

---

## ğŸš€ Features

- **Fineâ€‘Tuned Precision** â€“ Optimized using the Opus Books dataset for literaryâ€‘style translations.
- **Stateâ€‘ofâ€‘theâ€‘Art Architecture** â€“ Built on top of the MarianMT architecture.
- **FastAPI Backend** â€“ Readyâ€‘toâ€‘use REST API for single and batch translations.
- **Easy Integration** â€“ Uses Hugging Face `pipeline` for seamless translation.
- **Evaluation Metrics** â€“ Rigorously evaluated using BLEU scores with `sacrebleu`.

## ğŸ› ï¸ Technology Stack

- **Python**
- **Hugging Face Transformers**
- **Datasets** (Hugging Face)
- **Evaluate & SacreBLEU**
- **PyTorch / TensorFlow** (backend)
- **FastAPI & Uvicorn** (API server)

## ğŸ“¦ Installation & Requirements

```bash
# Install all dependencies (including the API server)
pip install -r requirements.txt
```

## ğŸ“‚ Repository Structure

```
â”œâ”€ app.py               # FastAPI server exposing the translation model
â”œâ”€ requirements.txt     # Python dependencies
â”œâ”€ my_translation_model # Fineâ€‘tuned model files (config, tokenizer, weights)
â”œâ”€ model.ipynb          # Jupyter notebook used for training
â”œâ”€ README.md            # This documentation
â””â”€ .gitignore          # Ignores virtual env & caches
```

## â–¶ï¸ Running the API Server

```bash
# Activate your virtual environment if you have one
# python -m venv venv && source venv/bin/activate   (Windows: venv\Scripts\activate)

# Start the server
python app.py
```
The server will be available at `http://localhost:8000`. Swagger UI can be accessed at `http://localhost:8000/docs`.

## ğŸ“¡ API Endpoints

| Method | Path | Description |
|--------|------|-------------|
| `GET`  | `/` | Health check â€“ returns service status and available endpoints |
| `GET`  | `/health` | Detailed health check with model metadata |
| `POST` | `/translate` | Translate a single English sentence to French |
| `POST` | `/translate/batch` | Translate a list of English sentences (maxâ€¯50 per request) |

### Request / Response examples
#### Single translation
```json
POST /translate
{
  "text": "Hello, how are you?",
  "max_length": 128
}
```
```json
Response:
{
  "original_text": "Hello, how are you?",
  "translated_text": "Bonjour, comment allezâ€‘vous?",
  "source_language": "en",
  "target_language": "fr"
}
```
#### Batch translation
```json
POST /translate/batch
{
  "texts": ["I love reading books.", "Machine learning is fascinating."],
  "max_length": 128
}
```
```json
Response:
{
  "translations": [
    {"original_text": "I love reading books.", "translated_text": "J'aime lire des livres."},
    {"original_text": "Machine learning is fascinating.", "translated_text": "L'apprentissage automatique est fascinant."}
  ]
}
```

## ğŸ§  Model Training (unchanged)

The training process involves:
1. **Tokenizer** â€“ `MarianTokenizer`
2. **Model** â€“ `MarianMTModel` preâ€‘trained on Englishâ€‘French
3. **Preâ€‘processing** â€“ truncation & padding to a max length of 128 tokens
4. **Fineâ€‘tuning** â€“ `Seq2SeqTrainer` with mixedâ€‘precision (`fp16`)

### Hyperâ€‘parameters (example)
- Learning Rate: `3e-5`
- Batch Size: `8`
- Epochs: `1`
- Weight Decay: `0.01`

## ğŸ“Š Evaluation

The model performance is evaluated using the **BLEU** score:
```python
results = trainer.evaluate()
print(f"Final BLEU Score: {results['eval_bleu']:.2f}")
```

## ğŸ’¾ Saving the Model

The fineâ€‘tuned model is saved to `./my_finetuned_en_fr_translator` and can be zipped for deployment:
```bash
zip -r my_translation_model.zip my_finetuned_en_fr_translator
```

---

**Author**: [Your Name]
**License**: MIT
